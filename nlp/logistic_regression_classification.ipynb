{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666db97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import kagglehub\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9828a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression:\n",
    "\tdef __init__(self, input_size):\n",
    "\t\t# small random weights; scalar bias\n",
    "\t\tself.weights = np.random.normal(0, 0.01, input_size)\n",
    "\t\tself.bias = 0.0\n",
    "\n",
    "\tdef predict_prob(self, X):\n",
    "\t\tz = np.dot(X, self.weights) + self.bias\n",
    "\t\treturn 1 / (1 + np.exp(-z))\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\t\treturn 1 if self.predict_prob(X) >= 0.5 else 0\n",
    "\n",
    "\tdef train(self, X, y_true, lr = 0.01):\n",
    "\t\ty_pred = self.predict_prob(X)\n",
    "\t\tloss = y_pred - y_true\n",
    "\t\tloss = (y_true * np.log(y_pred + 1e-8) + (1-y_true) * np.log(1 - y_pred + 1e-8))\n",
    "\t\tself.weights -= lr * loss * X\n",
    "\t\tself.bias -= lr * loss\n",
    "\n",
    "class MultiLogisticRegression:\n",
    "\t\tdef __init__(self, input_size):\n",
    "\t\t\t# Initialize an np array with normal distribution\n",
    "\t\t\tself.weights = np.random.normal(0, 0.01, input_size)\n",
    "\t\t\tself.bias = np.zeros(input_size)\n",
    "   \t\t#self.bias = 0\n",
    "\n",
    "\t\tdef train(self, X, y, lr = 0.001):\n",
    "\t\t\tprobs_predict = self.predict(X)\n",
    "\t\t\tloss = - np.dot(np.log(probs_predict), y)\n",
    "   \n",
    "\t\t\tself.weights -= lr * (loss * X)\n",
    "\t\t\tself.bias -= lr * loss\n",
    "\n",
    "\t\tdef predict(self, X):\n",
    "\t\t\tz = np.dot(X, self.weights) + self.bias\n",
    "\t\t\tnormalizer = sum(z)\n",
    "\t\t\tprobs = z / normalizer\n",
    "   \n",
    "\t\t\treturn probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97a0d317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5729, 2)\n",
      "                                                   text spam\n",
      "3562  Subject: re : my son  vince ,  i left a messag...    0\n",
      "4119  Subject: financial maths course , part 2  vinc...    0\n",
      "4482  Subject: june 21 - 22 retail electricity confe...    0\n",
      "4211  Subject: re : enron default swaps  darrell ,  ...    0\n",
      "5604  Subject: re : power question  steve ,  elena c...    0\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"jackksoncsie/spam-email-dataset\")\n",
    "\n",
    "csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "csv_path = os.path.join(path, csv_files[0])\n",
    "\n",
    "dataset = pd.read_csv(csv_path, names=['text', 'spam'])\n",
    "print(dataset.shape)\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset.sample(frac=1, random_state=42)\n",
    "print(dataset.head())\n",
    "\n",
    "texts = dataset['text'].tolist()\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "dataset_vectors = X.toarray()\n",
    "dataset['vector'] = list(dataset_vectors)\n",
    "\n",
    "dataset[\"spam\"] = dataset[\"spam\"].apply(lambda x: 1 if x == '1' else 0)\n",
    "\n",
    "dataset_x, dataset_y = dataset.shape\n",
    "train_cut = int(0.8 * dataset_x)\n",
    "\n",
    "train_data, test_data = dataset[:train_cut], dataset[train_cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b63d083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4583/4583 [00:00<00:00, 6691.56it/s]\n",
      "Testing: 100%|██████████| 1146/1146 [00:00<00:00, 10502.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = BinaryLogisticRegression(dataset_vectors.shape[1])\n",
    "\n",
    "for index, row in tqdm(train_data.iterrows(), total=len(train_data), desc=\"Training\"):\n",
    "\tclassifier.train(row['vector'], row['spam'])\n",
    "\n",
    "correct_predictions = 0\n",
    "for index, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Testing\"):\n",
    "\tpredicted_label = classifier.predict(row['vector'])\n",
    "\t#print(f\"Predicted: {predicted_label}, Actual: {row['label']}\")\n",
    "\tif predicted_label == row['spam']:\n",
    "\t\tcorrect_predictions += 1\n",
    "print(f\"Accuracy: {correct_predictions / len(test_data) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2761cf",
   "metadata": {},
   "source": [
    "## Tests with Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28d521c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "0    1368\n",
      "1    1368\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balancing the dataset over spam\n",
    "spam_count = dataset['spam'].value_counts()\n",
    "min_count = spam_count.min()\n",
    "balanced_dataset = pd.concat([\n",
    "\tdataset[dataset['spam'] == label].sample(min_count, random_state=42) for label in spam_count.index \n",
    "])\n",
    "print(balanced_dataset['spam'].value_counts())\n",
    "\n",
    "dataset_x, dataset_y = balanced_dataset.shape\n",
    "train_cut = int(0.8 * dataset_x)\n",
    "train_data, test_data = balanced_dataset[:train_cut], balanced_dataset[train_cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef3da3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2188/2188 [00:00<00:00, 5944.34it/s]\n",
      "Testing: 100%|██████████| 548/548 [00:00<00:00, 10151.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = BinaryLogisticRegression(dataset_vectors.shape[1])\n",
    "\n",
    "for index, row in tqdm(train_data.iterrows(), total=len(train_data), desc=\"Training\"):\n",
    "\tclassifier.train(row['vector'], row['spam'])\n",
    "\n",
    "correct_predictions = 0\n",
    "for index, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Testing\"):\n",
    "\tpredicted_label = classifier.predict(row['vector'])\n",
    "\t#print(f\"Predicted: {predicted_label}, Actual: {row['label']}\")\n",
    "\tif predicted_label == row['spam']:\n",
    "\t\tcorrect_predictions += 1\n",
    "print(f\"Accuracy: {correct_predictions / len(test_data) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
