{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666db97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import kagglehub\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9828a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression:\n",
    "\tdef __init__(self, input_size):\n",
    "\t\t# small random weights; scalar bias\n",
    "\t\tself.weights = np.random.normal(0, 0.01, input_size)\n",
    "\t\tself.bias = 0.0\n",
    "\n",
    "\tdef predict_prob(self, X):\n",
    "\t\tz = np.dot(X, self.weights) + self.bias\n",
    "\t\treturn 1 / (1 + np.exp(-z))\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\t\treturn 1 if self.predict_prob(X) >= 0.5 else 0\n",
    "\n",
    "\tdef train(self, X, y_true, lr = 0.01):\n",
    "\t\ty_pred = self.predict_prob(X)\n",
    "\t\tloss = y_pred - y_true\n",
    "\t\tloss = (y_true * np.log(y_pred + 1e-8) + (1-y_true) * np.log(1 - y_pred + 1e-8))\n",
    "\t\tself.weights -= lr * loss * X\n",
    "\t\tself.bias -= lr * loss\n",
    "\n",
    "class MultiLogisticRegression:\n",
    "\tdef __init__(self, input_size, num_classes):\n",
    "\t\t# Initialize weight matrix (input_size x num_classes)\n",
    "\t\tself.weights = np.random.normal(0, 0.01, (input_size, num_classes))\n",
    "\t\tself.bias = np.zeros(num_classes)\n",
    "\t\tself.num_classes = num_classes\n",
    "\n",
    "\tdef train(self, X, y, lr = 0.001, label_smoothing = 0.0):\n",
    "\t\t# Apply label smoothing\n",
    "\t\ty_smoothed = y * (1 - label_smoothing) + label_smoothing / self.num_classes\n",
    "\t\t\n",
    "\t\tprobs_predict = self.predict_prob(X)\n",
    "\t\tloss = - np.sum(np.log(probs_predict + 1e-8) * y_smoothed)\n",
    "\n",
    "\t\tself.weights -= lr * np.outer(X, probs_predict - y_smoothed)\n",
    "\t\tself.bias -= lr * (probs_predict - y_smoothed)\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\t\tprobs = self.predict_prob(X)\n",
    "\t\treturn np.argmax(probs)\n",
    "\n",
    "\tdef predict_prob(self, X):\n",
    "\t\tz = np.dot(X, self.weights) + self.bias\n",
    "\t\t# Softmax\n",
    "\t\texp_z = np.exp(z - np.max(z))\n",
    "\t\tprobs = exp_z / np.sum(exp_z)\n",
    "\t\treturn probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643c54e",
   "metadata": {},
   "source": [
    "## Tests with Unbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97a0d317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5729, 2)\n",
      "                                                   text spam\n",
      "3562  Subject: re : my son  vince ,  i left a messag...    0\n",
      "4119  Subject: financial maths course , part 2  vinc...    0\n",
      "4482  Subject: june 21 - 22 retail electricity confe...    0\n",
      "4211  Subject: re : enron default swaps  darrell ,  ...    0\n",
      "5604  Subject: re : power question  steve ,  elena c...    0\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"jackksoncsie/spam-email-dataset\")\n",
    "\n",
    "csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "csv_path = os.path.join(path, csv_files[0])\n",
    "\n",
    "dataset = pd.read_csv(csv_path, names=['text', 'spam'])\n",
    "print(dataset.shape)\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset.sample(frac=1, random_state=42)\n",
    "print(dataset.head())\n",
    "\n",
    "texts = dataset['text'].tolist()\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "dataset_vectors = X.toarray()\n",
    "dataset['vector'] = list(dataset_vectors)\n",
    "\n",
    "dataset[\"spam\"] = dataset[\"spam\"].apply(lambda x: 1 if x == '1' else 0)\n",
    "\n",
    "dataset_x, dataset_y = dataset.shape\n",
    "train_cut = int(0.8 * dataset_x)\n",
    "\n",
    "train_data, test_data = dataset[:train_cut], dataset[train_cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63d083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4583/4583 [00:00<00:00, 6691.56it/s]\n",
      "Testing: 100%|██████████| 1146/1146 [00:00<00:00, 10502.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = BinaryLogisticRegression(dataset_vectors.shape[1])\n",
    "\n",
    "for index, row in tqdm(train_data.iterrows(), total=len(train_data), desc=\"Training\"):\n",
    "\tclassifier.train(row['vector'], row['spam'])\n",
    "\n",
    "correct_predictions = 0\n",
    "for index, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Testing\"):\n",
    "\tpredicted_label = classifier.predict(row['vector'])\n",
    "\t#print(f\"Predicted: {predicted_label}, Actual: {row['label']}\")\n",
    "\tif predicted_label == row['spam']:\n",
    "\t\tcorrect_predictions += 1\n",
    "print(f\"Accuracy: {correct_predictions / len(test_data) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2761cf",
   "metadata": {},
   "source": [
    "## Tests with Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28d521c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "0    1368\n",
      "1    1368\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balancing the dataset over spam\n",
    "spam_count = dataset['spam'].value_counts()\n",
    "min_count = spam_count.min()\n",
    "balanced_dataset = pd.concat([\n",
    "\tdataset[dataset['spam'] == label].sample(min_count, random_state=42) for label in spam_count.index \n",
    "])\n",
    "print(balanced_dataset['spam'].value_counts())\n",
    "\n",
    "dataset_x, dataset_y = balanced_dataset.shape\n",
    "train_cut = int(0.8 * dataset_x)\n",
    "train_data, test_data = balanced_dataset[:train_cut], balanced_dataset[train_cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3da3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2188/2188 [00:00<00:00, 5944.34it/s]\n",
      "Testing: 100%|██████████| 548/548 [00:00<00:00, 10151.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = BinaryLogisticRegression(dataset_vectors.shape[1])\n",
    "\n",
    "for index, row in tqdm(train_data.iterrows(), total=len(train_data), desc=\"Training\"):\n",
    "\tclassifier.train(row['vector'], row['spam'])\n",
    "\n",
    "correct_predictions = 0\n",
    "for index, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Testing\"):\n",
    "\tpredicted_label = classifier.predict(row['vector'])\n",
    "\t#print(f\"Predicted: {predicted_label}, Actual: {row['label']}\")\n",
    "\tif predicted_label == row['spam']:\n",
    "\t\tcorrect_predictions += 1\n",
    "print(f\"Accuracy: {correct_predictions / len(test_data) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb5b08",
   "metadata": {},
   "source": [
    "## Multi-Classification Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6219f84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(993, 2)\n",
      "         Genre                                               Poem\n",
      "214      Music  What is it you feel I asked Kurt when you list...\n",
      "335      Death  I might travel his death a creaking and swayin...\n",
      "505  Affection  My heart is what it was before,A house where p...\n",
      "313      Death  He gossips like my grandmother, this man with ...\n",
      "89       Music  I have oared and grieved, grieved and oared, t...\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"ramjasmaurya/poem-classification-nlp\")\n",
    "\n",
    "for f in os.listdir(path): \n",
    "    if f.endswith('.csv') and \"train\" in f:\n",
    "        train_dataset_path = os.path.join(path, f)\n",
    "    else:\n",
    "        test_dataset_path = os.path.join(path, f)\n",
    "        \n",
    "train_dataset = pd.read_csv(train_dataset_path, names=['Genre', 'Poem'])\n",
    "test_dataset = pd.read_csv(test_dataset_path, names=['Genre', 'Poem'])\n",
    "\n",
    "dataset = pd.concat([train_dataset, test_dataset], ignore_index=True)\n",
    "\n",
    "print(dataset.shape)\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset.sample(frac=1, random_state=42)\n",
    "print(dataset.head())\n",
    "\n",
    "texts = dataset['Poem'].tolist()\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "dataset_vectors = X.toarray()\n",
    "dataset['vector'] = list(dataset_vectors)\n",
    "\n",
    "# Convert genres to one-hot encoding\n",
    "genres = dataset['Genre'].unique()\n",
    "genre_to_onehot = {genre: np.eye(len(genres))[i] for i, genre in enumerate(genres)}\n",
    "dataset['genre_onehot'] = dataset['Genre'].apply(lambda x: genre_to_onehot[x])\n",
    "\n",
    "dataset_x, dataset_y = dataset.shape\n",
    "train_cut = int(0.8 * dataset_x)\n",
    "\n",
    "train_data, test_data = dataset[:train_cut], dataset[train_cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b44696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2425.69it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2473.82it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2447.43it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2591.98it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2835.15it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2662.10it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2838.10it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2888.58it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2894.13it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2844.76it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2864.07it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2860.71it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2880.85it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2607.08it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2786.01it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2668.62it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2673.40it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2631.03it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2745.43it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2324.39it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 1398.37it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 1864.44it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2320.81it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2591.60it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2765.29it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2596.39it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2393.91it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2599.41it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2480.76it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 1785.42it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2535.00it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2586.89it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2579.06it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2717.49it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2759.43it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2605.96it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2665.05it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 1805.31it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 1373.20it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2067.78it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2688.90it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2762.28it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2599.47it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2741.65it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2648.16it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2897.86it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2874.62it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2871.38it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2876.29it/s]\n",
      "Training: 100%|██████████| 791/791 [00:00<00:00, 2846.86it/s]\n",
      "Testing: 100%|██████████| 198/198 [00:00<00:00, 8638.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 42.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = MultiLogisticRegression(dataset_vectors.shape[1], len(genres))\n",
    "\n",
    "n_trainings = 50\n",
    "for _ in range(n_trainings):\n",
    "\tfor index, row in tqdm(train_data.iterrows(), total=len(train_data), desc=\"Training\"):\n",
    "\t\tclassifier.train(row['vector'], row['genre_onehot'], lr=0.04, label_smoothing=0)\n",
    "\n",
    "correct_predictions = 0\n",
    "for index, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Testing\"):\n",
    "\tpredicted_label = classifier.predict(row['vector'])\n",
    "\tpredicted_genre = genres[predicted_label]\n",
    "\t#print(f\"Predicted: {predicted_label}, Actual: {row['label']}\")\n",
    "\tif predicted_genre == row['Genre']:\n",
    "\t\tcorrect_predictions += 1\n",
    "print(f\"Accuracy: {correct_predictions / len(test_data) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
